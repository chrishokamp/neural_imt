{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# truncate each suffix hyp in the n-best list according to some heuristic with respect to the costs\n",
    "# visualize heatmap of confidence per-word -- visualize how this corresponds to optimal hypothesis truncation\n",
    "# evaluate performance as the heuristic changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now graph f1, precision, recall over threshold\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (14.0, 12.0)\n",
    "pylab.rcParams['axes.linewidth'] = 2. #set the value globally\n",
    "params = {'legend.fontsize': 20}\n",
    "#           'legend.linewidth': 2}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import numpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# newstest 2014\n",
    "# BASEDIR ='/media/1tb_drive/imt_models/newstest_2014_evaluation/'\n",
    "\n",
    "# BASEDIR ='/media/1tb_drive/imt_models/EN-DE-confidence-3layer_FINAL_STATES_l2_reg_model_baseline_internal_data_dropout0.5_' + \\\n",
    "#          'src_vocab80000_trg_vocab90000_emb300_rec1000_batch50'\n",
    "\n",
    "\n",
    "\n",
    "# HYP_BASEDIR = '/media/1tb_drive/imt_models/EN-DE-confidence-3layer_FINAL_STATES_PREDICTION_65000_iters_model_baseline_internal_data_dropout1.0_src_vocab80000_trg_vocab90000_emb300_rec1000_batch50'\n",
    "# BASEDIR ='/media/1tb_drive/imt_models/EN-DE-confidence-3layer-baseline-PREDICTION_internal_data_dropout1.0_src_vocab80000_trg_vocab90000_emb300_rec1000_batch50/'\n",
    "# hyps_file = os.path.join(HYP_BASEDIR, 'newstest2014.de.500.bpe.imt-hyps.out')\n",
    "\n",
    "# confidences_file = os.path.join(BASEDIR, 'newstest2014.de.500.bpe.imt-confidences.75000_iters.npz')\n",
    "# confidences_file = os.path.join(BASEDIR, 'newstest2014.de.500.bpe.imt-confidences.100000_iters.npz')\n",
    "# confidences_file = os.path.join(BASEDIR, 'newstest2014.de.500.bpe.imt-confidences.15000_iters.npz')\n",
    "\n",
    "# confidences_file = os.path.join(BASEDIR, 'newstest2014.de.500.bpe.imt-confidences.prediction_trained_10000_iters.npz')\n",
    "# confidences_file = os.path.join(BASEDIR, 'newstest2014.de.500.bpe.imt-confidences.prediction_trained_40000_iters.npz')\n",
    "# confidences_file = os.path.join(BASEDIR, 'newstest2014.de.500.bpe.imt-confidences.prediction_trained_90000_iters.npz')\n",
    "\n",
    "# w/ softmax feature\n",
    "# BASEDIR ='/media/1tb_drive/imt_models/EN-DE-confidence-3layer_FINAL_STATES_AND_SOFTMAX_l2_reg_model_internal_' + \\\n",
    "#         'data_dropout0.5_src_vocab80000_trg_vocab90000_emb300_rec1000_batch50/'\n",
    "# confidences_file = os.path.join(BASEDIR, 'newstest2014.de.500.bpe.imt-confidences.prediction_trained.5000_iters.npz')\n",
    "# confidences_file = os.path.join(BASEDIR, 'newstest2014.de.500.bpe.imt-confidences.prediction_trained.25000_iters.npz')\n",
    "# confidences_file = os.path.join(BASEDIR, 'newstest2014.de.500.bpe.imt-confidences.prediction_trained.30000_iters.npz')\n",
    "# confidences_file = os.path.join(BASEDIR, 'newstest2014.de.500.bpe.imt-confidences.prediction_trained.35000_iters.npz')\n",
    "\n",
    "# w/ real dropout = 0.2\n",
    "# confidences_file = os.path.join(BASEDIR, 'newstest2014.de.500.bpe.imt-confidences.prediction_trained.10000_iters.npz')\n",
    "# confidences_file = os.path.join(BASEDIR, 'newstest2014.de.500.bpe.imt-confidences.prediction_trained.30000_iters.npz')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# w/ real dropout = 0.5\n",
    "# confidences_file = os.path.join(BASEDIR, 'newstest2014.de.500.bpe.imt-confidences.prediction_trained.35000_iters.npz')\n",
    "# confidences_file = os.path.join(BASEDIR, 'newstest2014.de.500.bpe.imt-confidences.prediction_trained.10000_iters.npz')\n",
    "\n",
    "# Final Evaluation:\n",
    "# w/ softmax feature and dropout = 0.5\n",
    "BASEDIR='/home/chris/Desktop/Dropbox/thesis/archived_models/imt_confidence_models/' + \\\n",
    "'EN-DE-confidence-3layer_FINAL_STATES_AND_SOFTMAX_l2_reg_model_internal_data_dropout0.5' + \\\n",
    "'_src_vocab80000_trg_vocab90000_emb300_rec1000_batch50'\n",
    "confidences_file = os.path.join(BASEDIR, 'newstest2014.de.500.bpe.imt-confidences.prediction_trained.10000_iters.npz')\n",
    "#HYP_BASEDIR = '/media/1tb_drive/imt_models/EN-DE-confidence-3layer_FINAL_STATES_PREDICTION_65000_iters_model_baseline_internal_data_dropout1.0_src_vocab80000_trg_vocab90000_emb300_rec1000_batch50'\n",
    "#hyps_file = os.path.join(HYP_BASEDIR, 'newstest2014.de.500.bpe.imt-hyps.out')\n",
    "hyps_file = os.path.join(BASEDIR, 'newstest2014.de.500.bpe.imt-hyps.out')\n",
    "\n",
    "wl_costs_file = os.path.join(BASEDIR, 'newstest2014.de.500.bpe.imt-word_level_costs.npz')\n",
    "\n",
    "source_file = os.path.join(BASEDIR, 'newstest2014.de.500.bpe.imt-sources.out')\n",
    "refs_file = os.path.join(BASEDIR, 'reference_suffixes.generated')\n",
    "\n",
    "prefixes_file = os.path.join(BASEDIR, 'reference_prefixes.generated')\n",
    "\n",
    "# newstest 2015\n",
    "# BASEDIR ='/media/1tb_drive/imt_models/newstest_2015_evaluation/'\n",
    "\n",
    "# hyps_file = os.path.join(BASEDIR, 'newstest2015.de.500.bpe.imt-hyps.out')\n",
    "# glimpse_file = os.path.join(BASEDIR, 'newstest2015.de.500.bpe.imt-glimpses.out')\n",
    "# source_file = os.path.join(BASEDIR, 'newstest2015.de.500.bpe.imt-sources.out')\n",
    "# refs_file = os.path.join(BASEDIR, 'reference_suffixes.generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lines(filename, lower=False, cutoff=None):\n",
    "    with codecs.open(filename) as inp:\n",
    "        lines = [l.split() for l in inp.read().strip().split('\\n')][:cutoff]\n",
    "        if lower:\n",
    "            lines = [[w.lower() for w in l] for l in lines]\n",
    "        return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orig_hyp_lines = get_lines(hyps_file)\n",
    "orig_ref_lines = get_lines(refs_file)\n",
    "orig_source_lines = get_lines(source_file)\n",
    "orig_prefix_lines = get_lines(prefixes_file)\n",
    "\n",
    "orig_word_level_confs = [l[0] for l in numpy.load(open(confidences_file))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(orig_word_level_confs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WORKING: evaluate use of word-level confs\n",
    "# HACKED HERE - WATCH THE NAME\n",
    "# costs are negative log probabilities, so convert them back to probailities\n",
    "orig_word_level_costs = [list(np.exp(-np.array(l[0]))) for l in numpy.load(open(wl_costs_file))]\n",
    "\n",
    "# orig_word_level_confs = [list(np.exp(-np.array(l[0]))) for l in numpy.load(open(wl_costs_file))]\n",
    "# orig_word_level_confs = [np.random.random(len(l)) for l in orig_word_level_confs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for p,c in zip(orig_hyp_lines, orig_word_level_confs):               \n",
    "    try:\n",
    "        assert len(p) == len(c)\n",
    "    except AssertionError:\n",
    "        print('P: {}, C: {}'.format(p,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.14305685,\n",
       "  0.80857545,\n",
       "  0.79699302,\n",
       "  0.15560581,\n",
       "  0.74367094,\n",
       "  0.69421959,\n",
       "  0.72801399,\n",
       "  0.95534259],\n",
       " [0.80857545,\n",
       "  0.79699302,\n",
       "  0.15560581,\n",
       "  0.74367094,\n",
       "  0.69421959,\n",
       "  0.72801399,\n",
       "  0.95534259],\n",
       " [0.79699302, 0.15560581, 0.74367094, 0.69421959, 0.72801399, 0.95534259],\n",
       " [0.15560581, 0.74367094, 0.69421959, 0.72801399, 0.95534259]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_word_level_confs[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(orig_word_level_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_cost_lines = [zip(hyp, ref_line, wl_costs) for hyp, ref_line, wl_costs in zip(orig_hyp_lines, orig_ref_lines, orig_word_level_costs)]\n",
    "word_conf_lines = [zip(hyp, ref_line, wl_costs) for hyp, ref_line, wl_costs in zip(orig_hyp_lines, orig_ref_lines, orig_word_level_confs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Gut@@', 'Gut@@', 0.95099431),\n",
       "  ('ach', 'ach', 0.98607504),\n",
       "  (':', ':', 0.99800879),\n",
       "  ('Mehr', 'Noch', 0.13394342),\n",
       "  ('Sicherheit', 'mehr', 0.97616267),\n",
       "  ('f\\xc3\\xbcr', 'Sicherheit', 0.95611227),\n",
       "  ('Fu\\xc3\\x9fg\\xc3\\xa4nger', 'f\\xc3\\xbcr', 0.60691315),\n",
       "  ('</S>', 'Fu\\xc3\\x9fg\\xc3\\xa4nger', 0.99937075)],\n",
       " [('ach', 'ach', 0.98607504),\n",
       "  (':', ':', 0.99800879),\n",
       "  ('Mehr', 'Noch', 0.13394329),\n",
       "  ('Sicherheit', 'mehr', 0.97616267),\n",
       "  ('f\\xc3\\xbcr', 'Sicherheit', 0.95611227),\n",
       "  ('Fu\\xc3\\x9fg\\xc3\\xa4nger', 'f\\xc3\\xbcr', 0.60691196),\n",
       "  ('</S>', 'Fu\\xc3\\x9fg\\xc3\\xa4nger', 0.99937075)],\n",
       " [(':', ':', 0.99800879),\n",
       "  ('Mehr', 'Noch', 0.13394316),\n",
       "  ('Sicherheit', 'mehr', 0.97616267),\n",
       "  ('f\\xc3\\xbcr', 'Sicherheit', 0.95611227),\n",
       "  ('Fu\\xc3\\x9fg\\xc3\\xa4nger', 'f\\xc3\\xbcr', 0.60691315),\n",
       "  ('</S>', 'Fu\\xc3\\x9fg\\xc3\\xa4nger', 0.99937075)]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_cost_lines[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg model probability of wrong predictions: 0.604707598686\n",
      "Avg model probability of correct predictions: 0.766623795033\n",
      "Avg confidence of wrong predictions: 0.503387391567\n",
      "Avg confidence of correct predictions: 0.62818980217\n",
      "total num predictions: 179008\n",
      "Pearson corr. between confidence model and IMT model cost: (0.84218478, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# mean confidence of wrong vs mean confidence of right\n",
    "wrong_probs = [v for r in word_cost_lines for hyp_w, ref_w, v  in r if hyp_w != ref_w]\n",
    "print('Avg model probability of wrong predictions: {}'.format(numpy.mean(wrong_probs)))\n",
    "right_probs = [v for r in word_cost_lines for hyp_w, ref_w, v  in r if hyp_w == ref_w]\n",
    "print('Avg model probability of correct predictions: {}'.format(numpy.mean(right_probs)))\n",
    "\n",
    "wrong_confs = [v for r in word_conf_lines for hyp_w, ref_w, v  in r if hyp_w != ref_w]\n",
    "print('Avg confidence of wrong predictions: {}'.format(numpy.mean(wrong_confs)))\n",
    "right_confs = [v for r in word_conf_lines for hyp_w, ref_w, v  in r if hyp_w == ref_w]\n",
    "print('Avg confidence of correct predictions: {}'.format(numpy.mean(right_confs)))\n",
    "\n",
    "# TODO: correlation between confidence and model probability\n",
    "from scipy.stats import pearsonr\n",
    "conf_model_values = [v for r in word_conf_lines for hyp_w, ref_w, v  in r]\n",
    "model_cost_values = [v for r in word_cost_lines for hyp_w, ref_w, v  in r]\n",
    "conf_vs_cost_pearson = pearsonr(conf_model_values, model_cost_values)\n",
    "assert len(model_cost_values) == len(conf_model_values)\n",
    "print('total num predictions: {}'.format(len(conf_model_values)))\n",
    "print('Pearson corr. between confidence model and IMT model cost: {}'.format(conf_vs_cost_pearson))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0026667719,\n",
       " 0.0026667733,\n",
       " 0.0037965546,\n",
       " 0.0042370493,\n",
       " 0.0042686076,\n",
       " 0.0046176556,\n",
       " 0.0046176622,\n",
       " 0.0046176664,\n",
       " 0.0046878643,\n",
       " 0.0047026989)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_cost, sorted_conf = zip(*sorted([(cost, conf) for cost, conf in zip(model_cost_values, conf_model_values)]))\n",
    "sorted_cost[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-8f2a7b39d01c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msorted_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msorted_conf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mslope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinregress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mconf_regression_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslope\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mintercept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stats' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "x = np.arange(0, len(conf_model_values), 100)\n",
    "\n",
    "# sort pairs by cost ascending, select every k-th point for efficiency\n",
    "sorted_cost, sorted_conf = zip(*sorted([(cost, conf) for cost, conf in zip(model_cost_values, conf_model_values)]))\n",
    "sorted_cost = [sorted_cost[i] for i in x]\n",
    "sorted_conf = [sorted_conf[i] for i in x]\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, sorted_conf)\n",
    "conf_regression_line = slope*x+intercept\n",
    "\n",
    "plt.plot(x, sorted_cost)\n",
    "plt.plot(x, sorted_conf)\n",
    "plt.plot(x, conf_regression_line)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7QAAAMGCAYAAADCxcjQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAACoJGgBAACoJGgBAACoJGgBAACo9P8Aus/qask4S34AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd3231a0a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hyp_words, ref_words, probs = zip(*word_cost_lines[0])\n",
    "\n",
    "# row_labels = hyp_words\n",
    "# column_labels = ['probability']\n",
    "# data = np.random.rand(4,4)\n",
    "# data = np.array(probs).reshape(1,len(probs))\n",
    "# fig, ax = plt.subplots()\n",
    "# heatmap = ax.pcolor(data, cmap=plt.cm.Blues)\n",
    "\n",
    "# # put the major ticks at the middle of each cell\n",
    "# ax.set_xticks(np.arange(data.shape[0])+0.5, minor=False)\n",
    "# ax.set_yticks(np.arange(data.shape[1])+0.5, minor=False)\n",
    "\n",
    "# # want a more natural, table-like display\n",
    "# ax.invert_yaxis()\n",
    "# ax.xaxis.tick_top()\n",
    "\n",
    "# ax.set_xticklabels(row_labels)\n",
    "# ax.set_yticklabels(column_labels, minor=False)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import plotly.plotly as py\n",
    "# import plotly.graph_objs as go\n",
    "\n",
    "# data = [\n",
    "#     go.Heatmap(\n",
    "#         z=[[30, 60, 1, -10, 20]],\n",
    "#         x=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'],\n",
    "#         y=['Morning']\n",
    "#     )\n",
    "# ]\n",
    "# colorscale = [[0, 'red'], [1, 'green']]  # custom colorscale\n",
    "\n",
    "# data = [\n",
    "#     go.Heatmap(\n",
    "#         z=[list(probs)],\n",
    "#         x=list(hyp_words),\n",
    "#         y=['probability'],\n",
    "#         colorscale=colorscale\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "\n",
    "# py.iplot(data, filename='labelled-heatmap')\n",
    "# print(ref_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRAINING SETUP BRAINSTORM\n",
    "# for each hyp, for each position, evaluate whether the prediction was correct\n",
    "\n",
    "# if the prediction was correct, this is a 1.\n",
    "\n",
    "# if not, this is a 0.\n",
    "\n",
    "# find the optimal coefficient/decision boundary for the single word-prob feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now evaluate different pruning strategies\n",
    "# BASELINE SCORES (NO TRUNCATION):INFO:__main__:IMT F1 SCORE: 0.244294277012, precision: 0.245880568086, recall: 0.244141178125\n",
    "\n",
    "# TODO: cost is a better measure of risk?? -- what is the logic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12812, 12812, 12812, 12812, 12812]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(l) for l in (orig_source_lines, orig_hyp_lines, orig_ref_lines, orig_word_level_confs, orig_prefix_lines)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12812\n",
      "6089\n",
      "5137\n"
     ]
    }
   ],
   "source": [
    "orig_trans_tups = zip(orig_source_lines, orig_hyp_lines, orig_ref_lines, orig_word_level_confs, orig_prefix_lines)\n",
    "print(len(orig_trans_tups))\n",
    "# discard rows where nothing matches\n",
    "matching_idxs = [idx for idx,t in enumerate(orig_trans_tups) if t[1][0] == t[2][0]]\n",
    "non_matching_idxs = [idx for idx,t in enumerate(orig_trans_tups) if t[1][0] != t[2][0]]\n",
    "\n",
    "# long_tups = [t for t in orig_trans_tups if len(t[1]) >= 7 and len(t[2]) >= 7]\n",
    "# matching_2_idxs = [idx for idx,t in enumerate(long_tups) if t[1][6] == t[2][6]]\n",
    "# non_2_matching_idxs = [idx for idx,t in enumerate(long_tups) if t[1][6] != t[2][6]]\n",
    "\n",
    "trans_tups = [t for t in orig_trans_tups if t[1][0] == t[2][0]]\n",
    "# trans_tups = orig_trans_tups\n",
    "\n",
    "# Filter to only longer predictions\n",
    "min_length_filter = 1\n",
    "trans_tups = [t for t in trans_tups if len(t[1]) >= min_length_filter]\n",
    "print(len(trans_tups))\n",
    "\n",
    "# But make sure they're not ridiculously long\n",
    "max_length_filter = 25\n",
    "trans_tups = [t for t in trans_tups if len(t[1]) <= max_length_filter]\n",
    "print(len(trans_tups))\n",
    "\n",
    "source_lines, hyp_lines, ref_lines, word_level_confs, prefix_lines = zip(*trans_tups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 479),\n",
       " (2, 423),\n",
       " (4, 292),\n",
       " (3, 288),\n",
       " (5, 254),\n",
       " (7, 234),\n",
       " (6, 233),\n",
       " (8, 228),\n",
       " (9, 214),\n",
       " (12, 211),\n",
       " (11, 201),\n",
       " (10, 196),\n",
       " (14, 187),\n",
       " (13, 181),\n",
       " (16, 174),\n",
       " (15, 171),\n",
       " (17, 163),\n",
       " (19, 148),\n",
       " (18, 143),\n",
       " (20, 130),\n",
       " (23, 130),\n",
       " (21, 126),\n",
       " (22, 123),\n",
       " (24, 108),\n",
       " (25, 100)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([len(t[1]) for t in trans_tups]).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_idxs = np.random.choice(len(trans_tups), size=10, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3719,  266, 2103, 1057, 4696, 2808, 4009, 4467, 3351, 5055])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_tups = [trans_tups[idx] for idx in random_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC: <S> Z@@ ita K@@ <UNK> , the Chair@@ person of the Parish Council , agreed to give a talk on Bi@@ blical pro@@ verb@@ s after breakfast . </S>\n",
      "PRE: <S> Z@@ ita K@@ öhler , die Vorsitzende des Kirchen@@ gemein@@ de@@ - rats , ging nach dem Frühstück in einem Vortrag auf die bibli@@ schen Sprich@@ wörter ein\n",
      "HYP: . </S>\n",
      "REF: . </S>\n",
      "\n",
      "\n",
      "SRC: <S> The catastrophes of his Catholic village up@@ bringing - the spe@@ ech@@ lessness , his tendency towards bru@@ te force and dul@@ led sexuality , the confin@@ ement and lack of joy - all of this has been described many times by the Ka@@ ern@@ ten-@@ born poet . </S>\n",
      "PRE: <S> Die Katastrophen seiner katholischen Dorf@@ kind@@ heit - die Sprach@@ losigkeit , der Hang zu ro@@ her Gewalt und stum@@ pf@@ er Sexualität , die En@@ ge und Fre@@ ud@@ losigkeit - hat der Kärn@@ tner Dichter vielfach\n",
      "HYP: beschrieben . </S>\n",
      "REF: beschrieben . </S>\n",
      "\n",
      "\n",
      "SRC: <S> The Nar@@ ren@@ zun@@ ft St@@ roh@@ gl@@ on@@ ki ( St@@ roh@@ gl@@ on@@ ki F@@ ool 's Guild celebration ) begins on 8 February with an evening of traditional customs on the occasion of its 60-@@ year anniversary / The Harmonie Gut@@ mad@@ ingen music association will turn 90 years old and on 29 March will hold a celebr@@ atory banquet and then from 1 to 4 May will be celebrating the Bezirks@@ fest [ District Music Festival ] . </S>\n",
      "PRE: <S> Die Nar@@ ren@@ zun@@ ft St@@ roh@@ gl@@ on@@ ki beginnt am 8. Februar mit einem Brau@@ cht@@ ums@@ abend anlässlich ihres 60-@@ jährigen Bestehens , die Harmonie Gut@@ mad@@ ingen wird 90 Jahre und hat am 29.\n",
      "HYP: März dieses Jahr zu feiern . </S>\n",
      "REF: März das Fest@@ bank@@ ett und feiert dann vom 1. bis 4. Mai das Bezirks@@ musik@@ fest . </S>\n",
      "\n",
      "\n",
      "SRC: <S> A short-@@ circuit was reported to have occurred there during sa@@ wing . </S>\n",
      "PRE: <S> Dort soll beim Sä@@ gen ein Kurz@@ schluss entstanden\n",
      "HYP: sein . </S>\n",
      "REF: sein . </S>\n",
      "\n",
      "\n",
      "SRC: <S> The access roads were blocked off , which , according to CNN , caused long tail@@ backs . </S>\n",
      "PRE: <S> Die Zu@@ fahrts@@ straßen wurden gesperrt , wodurch sich laut CNN lange Rück@@ st@@ aus bildeten .\n",
      "HYP: </S>\n",
      "REF: </S>\n",
      "\n",
      "\n",
      "SRC: <S> Eight years later it will reach Jupiter and will investigate the atmosphere of the planet as well as the icy mo@@ ons Europa , C@@ alli@@ sto and G@@ any@@ me@@ de . </S>\n",
      "PRE: <S> Acht Jahre später erreicht sie Jupiter und soll die Atmosphäre des Planeten sowie die ei@@ sigen Monde Europa , K@@ alli@@ sto und G@@ any@@ med untersuchen .\n",
      "HYP: </S>\n",
      "REF: </S>\n",
      "\n",
      "\n",
      "SRC: <S> The formerly super secre@@ tive N@@ SA , once nick@@ named No Such Agency , has found itself in very public light , and amid vicious criticism , in past months following a stream of revelations about is vast foreign and domestic surveillance programs - collectively the product of secret N@@ SA files stolen from the agency and leaked by disen@@ chanted former N@@ SA contractor Edward Snow@@ den . </S>\n",
      "PRE: <S> Die früher super@@ geheime N@@ SA , deren Spitz@@ name einst No Such Agency ( Keine solche Behörde ) lautete , findet sich inzwischen im hellen Licht der Öffentlichkeit und sieht sich nach den in den letzten Monaten bekannt gewordenen Enthüll@@ ungen über ihr ausgedeh@@ n@@ tes Überwachungs@@ programm im In- und Ausland schar@@ fer Kritik ausgesetzt – ein Resultat der geheimen N@@ SA-@@ Daten , die vom des@@\n",
      "HYP: illu@@ sion@@ ierten früheren N@@ SA-@@ Auftragnehmer Edward Snow@@ den er@@ gangen sind . </S>\n",
      "REF: illu@@ sion@@ ierten ehemaligen N@@ SA-@@ Mitarbeiter Edward Snow@@ den gestohlen und veröffentlicht wurden . </S>\n",
      "\n",
      "\n",
      "SRC: <S> Bombar@@ dier , the world 's largest train@@ maker , said revenue in that division rose nearly 11 percent to $ 2.1 billion . </S>\n",
      "PRE: <S> Bombar@@ dier , der weltweit größte Eisenbahn@@ hersteller , gab bekannt , dass der Umsatz in dieser Spar@@\n",
      "HYP: te fast 11 Prozent auf 2,@@ 1 Milliarden Dollar gestiegen ist . </S>\n",
      "REF: te um knapp elf Prozent auf 2,@@ 1 Milliarden Dollar gestiegen ist . </S>\n",
      "\n",
      "\n",
      "SRC: <S> F@@ ees are one way to get passengers to bring less on board . </S>\n",
      "PRE: <S> Gebühren sind eine\n",
      "HYP: Möglichkeit , die Fahrgäste an Bord zu bringen . </S>\n",
      "REF: Möglichkeit , Passagiere dazu zu bewegen , weniger mit an Bord zu nehmen . </S>\n",
      "\n",
      "\n",
      "SRC: <S> Some of his communications will undoubtedly have been legitimate ones because he was their lawyer . </S>\n",
      "PRE: <S> Ein Teil seiner Mitteilungen war zweifellos legitim , denn er\n",
      "HYP: war ein Rechtsanwalt . </S>\n",
      "REF: war der Anwalt dieser Personen . </S>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in sample_tups:\n",
    "    print(u\"SRC: {}\".format(' '.join(t[0])))\n",
    "    print(u\"PRE: {}\".format(' '.join(t[-1])))\n",
    "    print(u\"HYP: {}\".format(' '.join(t[1])))\n",
    "    print(u\"REF: {}\".format(' '.join(t[2])))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_s, random_h, random_r, random_c, random_p = zip(*sample_tups)\n",
    "hyp_ref_conf = [zip(h, r, c1, c2) for h,r,c1,c2 in \n",
    "                zip(random_h, random_r, [np.exp(np.cumsum(np.log(conf))) for conf in random_c], random_c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'.', u'.', 0.84726018, 0.84726018)\n",
      "(u'</S>', u'</S>', 0.81697655, 0.964257)\n",
      "\n",
      "\n",
      "\n",
      "(u'beschrieben', u'beschrieben', 0.30631727, 0.3063173)\n",
      "(u'.', u'.', 0.28119463, 0.91798484)\n",
      "(u'</S>', u'</S>', 0.27146229, 0.96538925)\n",
      "\n",
      "\n",
      "\n",
      "(u'M\\xe4rz', u'M\\xe4rz', 0.84594959, 0.84594959)\n",
      "(u'dieses', u'das', 0.27567583, 0.32587737)\n",
      "(u'Jahr', u'Fest@@', 0.14177892, 0.51429582)\n",
      "(u'zu', u'bank@@', 0.026616225, 0.18773048)\n",
      "(u'feiern', u'ett', 0.013982063, 0.52532101)\n",
      "(u'.', u'und', 0.01259432, 0.90074837)\n",
      "(u'</S>', u'feiert', 0.012121725, 0.96247536)\n",
      "\n",
      "\n",
      "\n",
      "(u'sein', u'sein', 0.43006381, 0.43006381)\n",
      "(u'.', u'.', 0.19933277, 0.46349579)\n",
      "(u'</S>', u'</S>', 0.18506782, 0.92843652)\n",
      "\n",
      "\n",
      "\n",
      "(u'</S>', u'</S>', 0.95689154, 0.95689154)\n",
      "\n",
      "\n",
      "\n",
      "(u'</S>', u'</S>', 0.96380103, 0.96380103)\n",
      "\n",
      "\n",
      "\n",
      "(u'illu@@', u'illu@@', 0.27701902, 0.27701902)\n",
      "(u'sion@@', u'sion@@', 0.10494244, 0.37882754)\n",
      "(u'ierten', u'ierten', 0.059535429, 0.5673151)\n",
      "(u'fr\\xfcheren', u'ehemaligen', 0.015691938, 0.26357311)\n",
      "(u'N@@', u'N@@', 0.0067147259, 0.42790934)\n",
      "(u'SA-@@', u'SA-@@', 0.0044841873, 0.66781396)\n",
      "(u'Auftragnehmer', u'Mitarbeiter', 0.0014493499, 0.32321346)\n",
      "(u'Edward', u'Edward', 0.00069032476, 0.47629952)\n",
      "(u'Snow@@', u'Snow@@', 0.0006565713, 0.95110488)\n",
      "(u'den', u'den', 0.00060101476, 0.91538376)\n",
      "(u'er@@', u'gestohlen', 9.3663708e-05, 0.15584268)\n",
      "(u'gangen', u'und', 3.3600358e-05, 0.35873398)\n",
      "(u'sind', u'ver\\xf6ffentlicht', 2.579902e-05, 0.76781964)\n",
      "(u'.', u'wurden', 2.4419662e-05, 0.94653469)\n",
      "(u'</S>', u'.', 2.33765e-05, 0.95728201)\n",
      "\n",
      "\n",
      "\n",
      "(u'te', u'te', 0.25407946, 0.25407946)\n",
      "(u'fast', u'um', 0.085060813, 0.3347804)\n",
      "(u'11', u'knapp', 0.039580479, 0.46531981)\n",
      "(u'Prozent', u'elf', 0.016607016, 0.41957587)\n",
      "(u'auf', u'Prozent', 0.0085440036, 0.51448154)\n",
      "(u'2,@@', u'auf', 0.0023464584, 0.27463219)\n",
      "(u'1', u'2,@@', 0.0017531533, 0.74714881)\n",
      "(u'Milliarden', u'1', 0.00085607276, 0.48830459)\n",
      "(u'Dollar', u'Milliarden', 0.00057078945, 0.66675353)\n",
      "(u'gestiegen', u'Dollar', 0.0001360786, 0.2384042)\n",
      "(u'ist', u'gestiegen', 6.6778586e-05, 0.49073526)\n",
      "(u'.', u'ist', 6.2367602e-05, 0.93394655)\n",
      "(u'</S>', u'.', 5.9968384e-05, 0.96153146)\n",
      "\n",
      "\n",
      "\n",
      "(u'M\\xf6glichkeit', u'M\\xf6glichkeit', 0.45972502, 0.45972502)\n",
      "(u',', u',', 0.15487619, 0.33688879)\n",
      "(u'die', u'Passagiere', 0.031033827, 0.20037828)\n",
      "(u'Fahrg\\xe4ste', u'dazu', 0.0060233222, 0.19408892)\n",
      "(u'an', u'zu', 0.0008268762, 0.13727906)\n",
      "(u'Bord', u'bewegen', 0.00035660635, 0.43126944)\n",
      "(u'zu', u',', 0.00011432791, 0.32059965)\n",
      "(u'bringen', u'weniger', 6.3487103e-05, 0.55530721)\n",
      "(u'.', u'mit', 5.6495523e-05, 0.88987428)\n",
      "(u'</S>', u'an', 5.4616212e-05, 0.96673489)\n",
      "\n",
      "\n",
      "\n",
      "(u'war', u'war', 0.76807207, 0.76807207)\n",
      "(u'ein', u'der', 0.14801049, 0.1927039)\n",
      "(u'Rechtsanwalt', u'Anwalt', 0.051664837, 0.349062)\n",
      "(u'.', u'dieser', 0.040973738, 0.79306823)\n",
      "(u'</S>', u'Personen', 0.039169375, 0.95596302)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# best thresh: \n",
    "\n",
    "for s in hyp_ref_conf:\n",
    "    print('\\n'.join(unicode(i) for i in s))\n",
    "    print('\\n\\n')\n",
    "# hyp_ref_conf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# true_first_confs = [orig_trans_tups[idx][3][0] for idx in matching_idxs]\n",
    "# wrong_first_confs = [orig_trans_tups[idx][3][0] for idx in non_matching_idxs]\n",
    "# print(np.mean(true_first_confs))\n",
    "# print(np.std(true_first_confs))\n",
    "# print(np.mean(wrong_first_confs))\n",
    "# print(np.std(wrong_first_confs))\n",
    "\n",
    "# true_2_confs = [long_tups[idx][3][0] for idx in matching_2_idxs]\n",
    "# wrong_2_confs = [long_tups[idx][3][0] for idx in non_2_matching_idxs]\n",
    "# print(np.mean(true_2_confs))\n",
    "# print(np.mean(wrong_2_confs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# minimum length of suffix is 1 (i.e. you have to predict something)\n",
    "# best aligned word must be at least this much bigger than average \n",
    "# pruning_threshold = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: visualize \"CUT\" index at best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prune_hyps_at_cumulative_threshold(threshold, tups, cutoff=1, good_thresh=None, bad_thresh=None):\n",
    "    pruned_hyps = []\n",
    "    \n",
    "    low_conf_idx = cutoff\n",
    "    for source, hyp, ref, confs, pre in tups:\n",
    "        confs = np.array(confs)\n",
    "        # weight confidence by position -- this is similar to a two-feature log-linear model\n",
    "#         for i, c in enumerate(confs):\n",
    "#             pos_weight = float(1./(i+1))\n",
    "#             confs[i] = min(1., c+pos_weight)\n",
    "        # intuition: shorter hyps can use the conf model, longer hyps wait for cutoff to use it    \n",
    "#         if len(hyp) <= cutoff:\n",
    "#             cutoff = 1\n",
    "    \n",
    "        # set confidence for points >= good_thresh = 1.\n",
    "        if good_thresh is not None:\n",
    "            confs[confs >= good_thresh] = 1.\n",
    "        if bad_thresh is not None:\n",
    "            confs[confs <= bad_thresh] = 0.001\n",
    "        \n",
    "        agg_confs = np.exp(np.cumsum(np.log(confs)))\n",
    "        for idx in range(cutoff,len(confs)):\n",
    "            if agg_confs[idx] <= threshold:\n",
    "                low_conf_idx = idx\n",
    "                break\n",
    "            \n",
    "        # HACK\n",
    "#         if len(hyp) <= 5:\n",
    "#             low_conf_idx = cutoff\n",
    "            \n",
    "        pruned_hyp = hyp[:low_conf_idx]\n",
    "        pruned_hyps.append(pruned_hyp)\n",
    "#         if len(pruned_hyp) < len(hyp) and len(pruned_hyp) > 3:\n",
    "#             print('original hyp: {}'.format(hyp))\n",
    "#             print('pruned hyp: {}'.format(pruned_hyp))\n",
    "#             print('ref: {}'.format(ref))\n",
    "    return pruned_hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prune_hyps_with_length_threshold(tups, threshold_dict, cutoff=1, num_buckets=20):\n",
    "    pruned_hyps = []\n",
    "    \n",
    "    low_conf_idx = cutoff\n",
    "    for source, hyp, ref, confs, pre in tups:\n",
    "        confs = np.array(confs)        \n",
    "        agg_confs = np.exp(np.cumsum(np.log(confs)))\n",
    "        hyp_len = len(hyp)\n",
    "        if len(hyp) < num_buckets:\n",
    "            threshold = threshold_dict[len(hyp)]\n",
    "        else:\n",
    "            threshold = threshold_dict[num_buckets]\n",
    "        \n",
    "        for idx in range(cutoff,len(confs)):\n",
    "            if agg_confs[idx] <= threshold:\n",
    "                low_conf_idx = idx\n",
    "                break\n",
    "            \n",
    "        pruned_hyp = hyp[:low_conf_idx]\n",
    "        pruned_hyps.append(pruned_hyp)\n",
    "\n",
    "    return pruned_hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prune_hyps_with_model(model, tups, cutoff=1, log=False):\n",
    "    pruned_hyps = []\n",
    "    \n",
    "    low_conf_idx = cutoff\n",
    "    for ins, (source, hyp, ref, confs, pre) in enumerate(tups):\n",
    "        confs = np.array(confs)\n",
    "        \n",
    "        agg_confs = np.exp(np.cumsum(np.log(confs)))\n",
    "        for idx in range(cutoff, len(confs)):\n",
    "#             feats = [float(idx), agg_confs[idx]]\n",
    "#             feats = [float(idx), confs[idx], agg_confs[idx]]\n",
    "            feats = [float(idx), confs[idx], agg_confs[idx]]\n",
    "\n",
    "            truncate = model.predict([feats])[0]\n",
    "            if truncate == 1.0:\n",
    "                low_conf_idx = idx\n",
    "                break\n",
    "        \n",
    "        if log:\n",
    "            top_match = [t[0] == t[1] for t in zip(hyp, ref)]\n",
    "            if False in top_match:\n",
    "                true_cutoff = top_match.index(False)\n",
    "            else:\n",
    "                true_cutoff = len(top_match)\n",
    "            print('actual best: {}'.format(true_cutoff))\n",
    "            print('model idx: {}'.format(low_conf_idx))\n",
    "        \n",
    "        pruned_hyp = hyp[:low_conf_idx]\n",
    "        pruned_hyps.append(pruned_hyp)\n",
    "#         if len(pruned_hyp) < len(hyp) and len(pruned_hyp) > 3:\n",
    "#             print('original hyp: {}'.format(hyp))\n",
    "#             print('pruned hyp: {}'.format(pruned_hyp))\n",
    "#             print('ref: {}'.format(ref))\n",
    "        if ins % 1000 == 0:\n",
    "            print('mapped ins: {}'.format(ins)) \n",
    "\n",
    "    return pruned_hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prune_hyps_at_threshold(threshold, tups, cutoff=1):\n",
    "    pruned_hyps = []\n",
    "    \n",
    "    low_conf_idx = cutoff\n",
    "    for source, hyp, ref, confs, pres in tups:\n",
    "        for idx in range(cutoff,len(confs)):\n",
    "            if confs[idx] <= threshold:\n",
    "                low_conf_idx = idx\n",
    "                break\n",
    "            \n",
    "        pruned_hyp = hyp[:low_conf_idx]\n",
    "        pruned_hyps.append(pruned_hyp)\n",
    "#         if len(pruned_hyp) < len(hyp):\n",
    "#             print('original hyp: {}'.format(hyp))\n",
    "#             print('pruned hyp: {}'.format(pruned_hyp))\n",
    "#             print('ref: {}'.format(ref))\n",
    "    return pruned_hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prune_hyps_at_cutoff(cutoff, tups):\n",
    "    pruned_hyps = []\n",
    "    for source, hyp, ref, confs, pres in tups:\n",
    "        pruned_hyp = hyp[:cutoff]\n",
    "        pruned_hyps.append(pruned_hyp)\n",
    "    return pruned_hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_ops_saved(hyp, ref):\n",
    "    match_len = 0\n",
    "    for h_sym, r_sym in zip(hyp, ref):\n",
    "        if h_sym == r_sym:\n",
    "            match_len += 1.\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # user needs to delete anything extra\n",
    "    del_ops = len(hyp) - match_len\n",
    "    ops_saved = match_len - del_ops\n",
    "    return ops_saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_hyp_len=max([len(h) for h in hyp_lines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_hyp_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_imt_truncation_feature_set(hyps, refs, confs, max_hyp_len=73):\n",
    "    # cut hyps to the point where they only match the ref prefix\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for hyp,ref,conf in zip(hyps, refs, confs):\n",
    "        cumulative_confs = np.exp(np.cumsum(np.log(conf)))\n",
    "\n",
    "        for i,hyp_w in zip(range(1,len(hyp)), hyp[1:]):\n",
    "#             feats = np.zeros(max_hyp_len + 1, dtype='float32')\n",
    "#             feats[i] = 1.\n",
    "#             feats[-1] = cumulative_confs[i]\n",
    "#             X.append(feats)\n",
    "            X.append([float(i), conf[i], cumulative_confs[i]])\n",
    "#             X.append([conf[i], cumulative_confs[i]])\n",
    "            \n",
    "#             already_stopped = False\n",
    "            if i < len(ref) and ref[i] == hyp_w:\n",
    "                y.append(0.)\n",
    "            else:\n",
    "                y.append(1.)\n",
    "                break\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_achievable(hyps, refs):\n",
    "    # cut hyps to the point where they only match the ref prefix\n",
    "    matching_hyps = []\n",
    "    for hyp,ref in zip(hyps, refs):\n",
    "        matching_hyp = []\n",
    "        for i,hyp_w in enumerate(hyp):\n",
    "            if i < len(ref) and ref[i] == hyp_w:\n",
    "                matching_hyp.append(hyp_w)\n",
    "            else:\n",
    "                break\n",
    "        matching_hyps.append(matching_hyp)\n",
    "    return matching_hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a feature set which includes: prev_word, current_word, position, conf_model --> stop/continue\n",
    "training_X, training_y = build_imt_truncation_feature_set(hyp_lines, ref_lines, word_level_confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10011"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# len_counts = Counter(len(h) for h in hyp_lines)\n",
    "# len_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75057436819498546"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = LogisticRegression()\n",
    "# clf = RandomForestClassifier()\n",
    "clf.fit(training_X, training_y)\n",
    "\n",
    "y_hat = clf.predict(training_X)\n",
    "sum(y_hat == training_y) / float(len(training_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOW compute IMT F1 for the pruned hyps, compare to IMT F1 for raw hyps\n",
    "from nn_imt.evaluation import imt_f1\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_imtF1(hyps, refs):\n",
    "    f1s, ps, rs = tuple(np.mean(m) for m in zip(*[imt_f1(h,r) for h,r in zip(hyps,refs)]))\n",
    "    return f1s, ps, rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_imtF1_scores(hyps, refs):\n",
    "    f1s, ps, rs = zip(*[imt_f1(h,r) for h,r in zip(hyps,refs)])\n",
    "    return f1s, ps, rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cutoffs = range(1,21)\n",
    "cutoff_sets = [prune_hyps_at_cutoff(cutoff, trans_tups) for cutoff in cutoffs]\n",
    "c_f1s, c_ps, c_rs = zip(*[avg_imtF1(cutoff_set, ref_lines) for cutoff_set in cutoff_sets]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ops_saved(hyps, refs):\n",
    "    return sum([num_ops_saved(hyp, ref) for hyp, ref in zip(hyps, refs)])\n",
    "\n",
    "def get_mean_ops_saved(hyps, refs):\n",
    "    return np.mean([num_ops_saved(hyp, ref) for hyp, ref in zip(hyps, refs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "6113.0\n",
      "1\n",
      "1.18999416002\n"
     ]
    }
   ],
   "source": [
    "set_ops_saved = [get_ops_saved(cutoff_set, ref_lines) for cutoff_set in cutoff_sets]\n",
    "mean_ops_saved = [get_mean_ops_saved(cutoff_set, ref_lines) for cutoff_set in cutoff_sets]\n",
    "\n",
    "print(np.argmax(set_ops_saved))\n",
    "print(np.max(set_ops_saved))\n",
    "print(np.argmax(mean_ops_saved))\n",
    "print(np.max(mean_ops_saved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.0, 1., num=50, endpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tups_by_hyp_len(trans_tups, num_buckets=20):\n",
    "    len_tups = {k:[] for k in range(num_buckets+1)}\n",
    "    for tup in trans_tups:\n",
    "        tup_len = len(tup[1])\n",
    "        if tup_len < num_buckets:\n",
    "            len_tups[tup_len].append(tup)\n",
    "        else:\n",
    "            len_tups[num_buckets].append(tup)\n",
    "    for k in len_tups.keys():\n",
    "        if len(len_tups[k]) == 0:\n",
    "            del len_tups[k]\n",
    "    return len_tups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_buckets = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tup_buckets = tups_by_hyp_len(trans_tups, num_buckets=num_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[479, 423, 288, 292, 254, 233, 234, 228, 214, 196]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(tup_buckets[k]) for k in range(10+1) if k in tup_buckets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: switch to choosing the pruning index based on num ops saved, not mean f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pruned_len_sets(tup_bucket_dict, thresholds, num_buckets=20):\n",
    "    len_thresholds = {}\n",
    "    for k in tup_bucket_dict.keys():\n",
    "        k_tups = tup_bucket_dict[k]\n",
    "        k_refs = zip(*k_tups)[2]\n",
    "#         k_pruned_sets = [prune_hyps_at_cumulative_threshold(thresh, k_tups) for thresh in thresholds]\n",
    "        \n",
    "        # WORKING: two dynamic pruning functions -- one for cutoff, one for thresh\n",
    "        # CUMULATIVE THRESHOLD\n",
    "        k_pruned_sets = [prune_hyps_at_cumulative_threshold(thresh, k_tups) for thresh in thresholds]\n",
    "        # TOKEN THRESHOLD\n",
    "#         k_pruned_sets = [prune_hyps_at_threshold(thresh, k_tups) for thresh in thresholds]\n",
    "\n",
    "        # CUTOFF -- currently HACKED\n",
    "#         thresholds = range(1,21)\n",
    "#         k_pruned_sets = [prune_hyps_at_cutoff(cutoff, k_tups) for cutoff in cutoffs]\n",
    "        \n",
    "        # get the best threshold for this index\n",
    "#         mean_f1s = [np.mean(all_imtF1_scores(k_pruned_set, k_refs)) for k_pruned_set in k_pruned_sets]\n",
    "        ops_saved = [get_ops_saved(k_pruned_set, k_refs) for k_pruned_set in k_pruned_sets]        \n",
    "    \n",
    "#         print(all_imtF1_scores(k_pruned_set, k_refs)[0])\n",
    "#         print(mean_f1s)\n",
    "#         print(len(mean_f1s))\n",
    "#         best_threshold = np.argmax(mean_f1s)\n",
    "        best_threshold = np.argmax(ops_saved)\n",
    "        print('length_bucket: {}'.format(k))\n",
    "        print('num_tups in bucket: {}'.format(len(k_tups)))\n",
    "        print('best threshold: {}'.format(thresholds[best_threshold]))\n",
    "        print('ops saved: {}'.format(ops_saved[best_threshold]))\n",
    "        print('\\n')\n",
    "        len_thresholds[k] = thresholds[best_threshold]\n",
    "    return len_thresholds\n",
    "        \n",
    "#     pruned_sets = [prune_hyps_at_cumulative_threshold(thresh, trans_tups) for thresh in thresholds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length_bucket: 1\n",
      "num_tups in bucket: 479\n",
      "best threshold: 0.0\n",
      "ops saved: 479.0\n",
      "\n",
      "\n",
      "length_bucket: 2\n",
      "num_tups in bucket: 423\n",
      "best threshold: 0.0\n",
      "ops saved: 423.0\n",
      "\n",
      "\n",
      "length_bucket: 3\n",
      "num_tups in bucket: 288\n",
      "best threshold: 0.0816326530612\n",
      "ops saved: 349.0\n",
      "\n",
      "\n",
      "length_bucket: 4\n",
      "num_tups in bucket: 292\n",
      "best threshold: 0.0612244897959\n",
      "ops saved: 328.0\n",
      "\n",
      "\n",
      "length_bucket: 5\n",
      "num_tups in bucket: 254\n",
      "best threshold: 0.30612244898\n",
      "ops saved: 328.0\n",
      "\n",
      "\n",
      "length_bucket: 6\n",
      "num_tups in bucket: 233\n",
      "best threshold: 0.224489795918\n",
      "ops saved: 323.0\n",
      "\n",
      "\n",
      "length_bucket: 7\n",
      "num_tups in bucket: 234\n",
      "best threshold: 0.142857142857\n",
      "ops saved: 313.0\n",
      "\n",
      "\n",
      "length_bucket: 8\n",
      "num_tups in bucket: 228\n",
      "best threshold: 0.102040816327\n",
      "ops saved: 280.0\n",
      "\n",
      "\n",
      "length_bucket: 9\n",
      "num_tups in bucket: 214\n",
      "best threshold: 0.265306122449\n",
      "ops saved: 252.0\n",
      "\n",
      "\n",
      "length_bucket: 10\n",
      "num_tups in bucket: 196\n",
      "best threshold: 0.204081632653\n",
      "ops saved: 233.0\n",
      "\n",
      "\n",
      "length_bucket: 11\n",
      "num_tups in bucket: 201\n",
      "best threshold: 0.367346938776\n",
      "ops saved: 241.0\n",
      "\n",
      "\n",
      "length_bucket: 12\n",
      "num_tups in bucket: 211\n",
      "best threshold: 0.224489795918\n",
      "ops saved: 246.0\n",
      "\n",
      "\n",
      "length_bucket: 13\n",
      "num_tups in bucket: 181\n",
      "best threshold: 0.30612244898\n",
      "ops saved: 230.0\n",
      "\n",
      "\n",
      "length_bucket: 14\n",
      "num_tups in bucket: 187\n",
      "best threshold: 0.265306122449\n",
      "ops saved: 230.0\n",
      "\n",
      "\n",
      "length_bucket: 15\n",
      "num_tups in bucket: 171\n",
      "best threshold: 0.326530612245\n",
      "ops saved: 214.0\n",
      "\n",
      "\n",
      "length_bucket: 16\n",
      "num_tups in bucket: 174\n",
      "best threshold: 0.30612244898\n",
      "ops saved: 206.0\n",
      "\n",
      "\n",
      "length_bucket: 17\n",
      "num_tups in bucket: 163\n",
      "best threshold: 0.30612244898\n",
      "ops saved: 216.0\n",
      "\n",
      "\n",
      "length_bucket: 18\n",
      "num_tups in bucket: 143\n",
      "best threshold: 0.163265306122\n",
      "ops saved: 214.0\n",
      "\n",
      "\n",
      "length_bucket: 19\n",
      "num_tups in bucket: 148\n",
      "best threshold: 0.163265306122\n",
      "ops saved: 202.0\n",
      "\n",
      "\n",
      "length_bucket: 20\n",
      "num_tups in bucket: 130\n",
      "best threshold: 0.122448979592\n",
      "ops saved: 201.0\n",
      "\n",
      "\n",
      "length_bucket: 21\n",
      "num_tups in bucket: 126\n",
      "best threshold: 0.122448979592\n",
      "ops saved: 169.0\n",
      "\n",
      "\n",
      "length_bucket: 22\n",
      "num_tups in bucket: 123\n",
      "best threshold: 0.163265306122\n",
      "ops saved: 165.0\n",
      "\n",
      "\n",
      "length_bucket: 23\n",
      "num_tups in bucket: 130\n",
      "best threshold: 0.163265306122\n",
      "ops saved: 190.0\n",
      "\n",
      "\n",
      "length_bucket: 24\n",
      "num_tups in bucket: 108\n",
      "best threshold: 0.122448979592\n",
      "ops saved: 168.0\n",
      "\n",
      "\n",
      "length_bucket: 25\n",
      "num_tups in bucket: 100\n",
      "best threshold: 0.102040816327\n",
      "ops saved: 154.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# WORKING: compute best threshold at each input length -- complexity = (n_lengths * n_thresholds)\n",
    "len_threshs = pruned_len_sets(tup_buckets, thresholds, num_buckets=num_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pruned_sets = [prune_hyps_at_threshold(thresh, trans_tups) for thresh in thresholds]\n",
    "pruned_sets = [prune_hyps_at_cumulative_threshold(thresh, trans_tups) for thresh in thresholds]\n",
    "\n",
    "t_f1s, t_ps, t_rs = zip(*[avg_imtF1(pruned_set, ref_lines) for pruned_set in pruned_sets])\n",
    "max_f1_idx = np.argmax(t_f1s)\n",
    "\n",
    "set_ops_saved = [get_ops_saved(pruned_set, ref_lines) for pruned_set in pruned_sets]\n",
    "mean_ops_saved = [get_mean_ops_saved(cutoff_set, ref_lines) for cutoff_set in cutoff_sets]\n",
    "\n",
    "dynamic_pruned_set = prune_hyps_with_length_threshold(trans_tups, len_threshs)\n",
    "dynamic_ops_saved = get_ops_saved(dynamic_pruned_set, ref_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6465.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_ops_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WORKING: normalize pruning function signatures, use func as argument to prune_hyps at length threshold\n",
    "# WORKING: also return thresholds from function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.0"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_ops_saved[max_f1_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "7012.0\n",
      "1\n",
      "1.17671210379\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(set_ops_saved))\n",
    "print(np.max(set_ops_saved))\n",
    "print(np.argmax(mean_ops_saved))\n",
    "print(np.max(mean_ops_saved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_f1s, raw_ps, raw_rs = avg_imtF1(hyp_lines, ref_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34692857370552443"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*((raw_ps*raw_rs) / (raw_ps+raw_rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_f1s, max_ps, max_rs = avg_imtF1(max_achievable(hyp_lines, ref_lines), ref_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50581646607974906"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*((max_ps*max_rs) / (max_ps+max_rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_thresh_f1s = [2*((p*r) / (p+r)) for p,r in zip(t_ps, t_rs)]\n",
    "avg_cutoff_f1s = [2*((p*r) / (p+r)) for p,r in zip(c_ps, c_rs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: there is a bug somewhere in f1_score computation -- either in IMT F1, or in the manual implementation\n",
    "# OR: it is different to compute mean_f1 vs f1 of mean p and mean r -- in general, YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.424002936235\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "best_cutoff_idx = np.argmax(avg_cutoff_f1s)\n",
    "# print(best_cutoff_idx)\n",
    "print(avg_cutoff_f1s[best_cutoff_idx])\n",
    "print(cutoffs[best_cutoff_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36740004011850053"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(t_f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3752621714650804"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(c_f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36819514488350419"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_cutoff_scores, _, _ = all_imtF1_scores(cutoff_sets[best_cutoff_idx], ref_lines)\n",
    "np.mean(best_cutoff_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# idea: combine threshold with the index you're cutting -- different optimal threshold depending on suffix length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapped ins: 0\n",
      "mapped ins: 1000\n",
      "mapped ins: 2000\n",
      "mapped ins: 3000\n",
      "mapped ins: 4000\n",
      "mapped ins: 5000\n",
      "mapped ins: 6000\n"
     ]
    }
   ],
   "source": [
    "# model_pruned_hyps = prune_hyps_with_model(clf, trans_tups[:100], log=True)\n",
    "model_pruned_hyps = prune_hyps_with_model(clf, trans_tups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model_scores, _, _ = all_imtF1_scores(model_pruned_hyps, ref_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31540191656749711"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(best_model_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0.415613684359\n",
      "0.0612244897959\n"
     ]
    }
   ],
   "source": [
    "best_thresh_idx = np.argmax(avg_thresh_f1s)\n",
    "print(best_thresh_idx)\n",
    "print(avg_thresh_f1s[best_thresh_idx])\n",
    "print(thresholds[best_thresh_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_ps: 0.690096896042, c_rs: 0.306009107301\n",
      "t_ps: 0.658703370167, t_rs: 0.303579776714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.33852365161102493)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('c_ps: {}, c_rs: {}'.format(c_ps[best_cutoff_idx], c_rs[best_cutoff_idx]))\n",
    "print('t_ps: {}, t_rs: {}'.format(t_ps[best_thresh_idx], t_rs[best_thresh_idx]))\n",
    "max_ps, max_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5362128428313353"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(i) for i in pruned_sets[best_thresh_idx]])\n",
    "# np.mean([len(i) for i in model_pruned_hyps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.368195144884\n",
      "0.361203927926\n"
     ]
    }
   ],
   "source": [
    "best_thresh_scores, _, _ = all_imtF1_scores(pruned_sets[best_thresh_idx], ref_lines)\n",
    "print(np.mean(best_cutoff_scores))\n",
    "print(np.mean(best_thresh_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_achievable_scores, _, _ = all_imtF1_scores(max_achievable(hyp_lines, ref_lines), ref_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41122585205817652"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(max_achievable_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1620"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([t > c for t,c in zip(best_thresh_scores, best_cutoff_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2522"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([c > t for t,c in zip(best_thresh_scores, best_cutoff_scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.065334836294145632"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([t - c for t,c in zip(best_thresh_scores, best_cutoff_scores) if t > c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058846928966136497"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([c -t for t,c in zip(best_thresh_scores, best_cutoff_scores) if c > t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6089"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(best_thresh_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# QUESTIONS:\n",
    "# Where does the confidence model fail? -- why is it bad for shorter predictions?\n",
    "#   Hypotheses:\n",
    "#   - not enough short training instances\n",
    "#   - threshold doesn't generalize well\n",
    "# Are good inputs getting shortened or bad inputs getting lengthened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.915421251437\n",
      "0.368861882082\n",
      "5574.0\n",
      "2246.0\n",
      "13567.0\n"
     ]
    }
   ],
   "source": [
    "# compute the avg number of operations saved \n",
    "print(np.mean([num_ops_saved(h, r) for h,r in zip(cutoff_sets[best_cutoff_idx], ref_lines)]))\n",
    "print(np.mean([num_ops_saved(h, r) for h,r in zip(pruned_sets[best_thresh_idx], ref_lines)]))\n",
    "print(sum([num_ops_saved(h, r) for h,r in zip(cutoff_sets[best_cutoff_idx], ref_lines)]))\n",
    "print(sum([num_ops_saved(h, r) for h,r in zip(pruned_sets[best_thresh_idx], ref_lines)]))\n",
    "print(sum([num_ops_saved(h, r) for h,r in zip(max_achievable(hyp_lines, ref_lines), ref_lines)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181.83333333333334"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10910 / 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.75"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "525 / 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04812107813213223"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8.75 / 181.833"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(t) for t in pruned_sets[best_thresh_idx]])\n",
    "# TODO: what is the maximum number of tokens matched by the threshold model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=3499500.5, pvalue=9.4541169726054271e-25)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# stats.ttest_ind(best_cutoff_scores, best_thresh_scores, equal_var=False)\n",
    "stats.wilcoxon(best_cutoff_scores, best_thresh_scores)\n",
    "# stats.ttest_rel(best_cutoff_scores, best_thresh_scores)\n",
    "\n",
    "# CONCLUSION: current model is _NOT_ significantly better than baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dump predictions to file\n",
    "output_f1s = zip(best_cutoff_scores, best_thresh_scores, max_achievable_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4353"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('model_scores.csv', 'w') as out:\n",
    "    out.write('Baseline, Model, Oracle\\n')\n",
    "    for r in output_f1s:\n",
    "        out.write(', '.join(str(f) for f in r) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# working -- np cumsum to get cumulative confidence\n",
    "# BASELINE -- cutoff = 3\n",
    "0.424002936235\n",
    "\n",
    "# threshold cumsum @10000 iters -- w/ cutoff 3\n",
    "9\n",
    "0.427885047471\n",
    "0.183673469388\n",
    "\n",
    "# threshold cumsum @10000 iters -- w/ cutoff 1\n",
    "6\n",
    "0.425319179877\n",
    "0.122448979592\n",
    "\n",
    "# threshold cumsum @40000 iters -- w/ cutoff 3\n",
    "10\n",
    "0.427649373976\n",
    "0.204081632653\n",
    "\n",
    "# threshold cumsum @40000 iters -- w/ cutoff 1\n",
    "6\n",
    "0.425204928317\n",
    "0.122448979592\n",
    "\n",
    "# threshold cumsum @75000 iters -- w/ cutoff 1\n",
    "5\n",
    "0.427151842361\n",
    "0.102040816327\n",
    "\n",
    "# threshold cumsum @75000 iters -- w/ cutoff 3\n",
    "6\n",
    "0.42848914907\n",
    "0.122448979592"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# pylab.rcParams.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_possible = .312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff2385be750>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1sAAALtCAYAAADe2H7ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nU7YMwzAMwzAMwzBywP8D/+27FoZxpYoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff2386d3590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "names = ['imt_f1_score', 'precision', 'recall']\n",
    "metrics = [avg_thresh_f1s, t_ps, t_rs]\n",
    "# styles = \t['solid' | 'dashed', 'dashdot', 'dotted' |\n",
    "styles = ['solid', 'dashed', 'dotted']\n",
    "\n",
    "\n",
    "# for i,key_points in enumerate(all_points):\n",
    "\n",
    "for i in range(len(names)):\n",
    "    name = names[i]\n",
    "    x = thresholds\n",
    "    y = metrics[i]\n",
    "#     ax.scatter(x, y, s=70, c='red')\n",
    "    plt.plot(x, y, 'k', label=name, linewidth=4.0, ls=styles[i])\n",
    "    \n",
    "    plt.ylim([0.3,0.7])\n",
    "    plt.xlim([0.0, .5])\n",
    "\n",
    "    \n",
    "    \n",
    "# fig.suptitle('test title')\n",
    "plt.xlabel('Alignment Weight Threshold', fontsize=28)\n",
    "plt.setp(ax.get_xticklabels(), fontsize=20)\n",
    "plt.setp(ax.get_yticklabels(), fontsize=20)\n",
    "ax.set_yticks(ax.get_yticks()[1:])\n",
    "\n",
    "# plt.setp(ax.get_xticklabels(), rotation='vertical', fontsize=14)\n",
    "# plt.ylabel('ylabel', fontsize=16)\n",
    "plt.legend()\n",
    "plt.legend(frameon=False)\n",
    "plt.legend(loc = 'upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.11111111,  0.22222222,  0.33333333,  0.44444444,\n",
       "        0.55555556,  0.66666667,  0.77777778,  0.88888889,  1.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresholds = np.linspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_f1s: 0.244294277012, raw_p: 0.245880568086, raw_r: 0.244141178125\n",
      "max f1s: 0.19325586391, max_p: 0.56001529052, max_r: 0.141309311685\n"
     ]
    }
   ],
   "source": [
    "# compare IMT F1 over matching hyps vs raw hyps\n",
    "raw_f1s, raw_p, raw_r = tuple(np.mean(m) for m in zip(*[imt_f1(h,r) for h,r in zip(hyp_lines,ref_lines)]))\n",
    "max_f1s, max_p, max_r = tuple(np.mean(m) for m in zip(*[imt_f1(h,r) for h,r in zip(pruned_hyps,ref_lines)]))\n",
    "\n",
    "print('raw_f1s: {}, raw_p: {}, raw_r: {}'.format(raw_f1s, raw_p, raw_r))\n",
    "print('max f1s: {}, max_p: {}, max_r: {}'.format(max_f1s, max_p, max_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now plot p, r, and f1 against alignment thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pruned_hyps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WORKING: for each target word, print the closest aligned source word\n",
    "window_size = 1\n",
    "top_n = 3\n",
    "for i,t_seq in enumerate(trans):\n",
    "    for j,w in enumerate(t_seq):\n",
    "        weights_ij = glimpses[i][j]\n",
    "        normed_weights = numpy.exp(weights_ij) / numpy.sum(numpy.exp(weights_ij))\n",
    "        aligned_word = numpy.argmax(weights_ij)\n",
    "        top_n_aligned_words = numpy.argsort(weights_ij)[::-1][:top_n]\n",
    "        top_n_aligned_weights = weights_ij[top_n_aligned_words]\n",
    "        percent_of_best = top_n_aligned_weights / top_n_aligned_weights[0]\n",
    "        best_weight = top_n_aligned_weights[0]\n",
    "        avg_weight = numpy.mean(weights_ij)\n",
    "        best_avg_percent = avg_weight / best_weight\n",
    "        top_n_src_idxs = [seq[s] for s in top_n_aligned_words]\n",
    "        src_aligned_idx_window = seq[aligned_word-window_size:aligned_word+window_size+1]\n",
    "        print('aligned window: {}'.format((self.trg_ivocab[w], [self.src_ivocab[sw] for sw in src_aligned_idx_window])))\n",
    "        print('top n aligned: {}'.format((self.trg_ivocab[w], [self.src_ivocab[sw] for sw in top_n_src_idxs])))\n",
    "        print('percent from best: {}'.format(percent_of_best))\n",
    "        # print('normed weights: {}'.format(weights_ij / numpy.sum(weights_ij)))\n",
    "        # print('weight distribution: {}'.format(normed_weights))\n",
    "import ipdb;ipdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glimpses[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(hyp_lines) == len(ref_lines) == len(glimpses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-9f98e48df3fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglimpses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: len() of unsized object"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notes BUFFER\n",
    "# Create the stream used to train a prediction confidence model\n",
    "\n",
    "# For the baseline, use the thresholded output probability of the word (i.e. the score given the history)\n",
    "\n",
    "# predict each segement, write out the cost for each word to file\n",
    "\n",
    "# do post-processing similar to glimpses for each word\n",
    "\n",
    "\n",
    "# NOTE: ambiguity, aka word-fertility is a consideration here -- \n",
    "# model should intuitively have lower confidence at positions which are ambiguous  \n",
    "\n",
    "# TODO: visualize confidence heatmap over outputs\n",
    "# TODO: What about forced decoding? how can we get the states, glimpses, and costs for a force-decoded input?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
